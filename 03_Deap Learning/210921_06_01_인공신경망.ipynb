{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인공신경망 (Artif- icial Neural Network : ANN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인공신경망 (Artif- icial Neural Network : ANN)\n",
    "- 인간의 뉴런 구조를 본떠 만든 기계학습 모델\n",
    "- 인간의 뉴런 동작 원리에 기초해 인공적으로 구축한 신경망 (기계학습 모델)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인공신경망의 종류\n",
    "- DNN(Deep Neural Network:심층 신경망)\n",
    "- Deep Feedforward Network (DFN)\n",
    "- RNN(Recurrent Neural Network : 순환 싱경망)\n",
    "- Long Short-Term Memory (LSTM)\n",
    "- CNN(Convolution Neural Network :  합성곱 신경망)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DNN(Deep Neural Network:심층 신경망)\n",
    "- 하나의 입력층과 하나의 출력증, 다수의 은닉층으로 구성\n",
    "- 무방향 이분 그래프 형태의 모양을 기반으로\n",
    "- 사전학습을 통해 어느 정도 보정을 한 후 튜닝의 과정을 거쳐 최종 가중치를 계산하는 방법\n",
    "- 레이블된 데이터 세트가 충분하지 않아도 적용 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Feedforward Network (DFN)\n",
    "- 딥러닝의 가장 기본적인 인공 신경망\n",
    "- 입력층, 은닉층, 출력층으로 구성\n",
    "- 2개 이상의 은닉층 사용\n",
    "- 입력 데이터는 입력층, 은닉층, 출력층의 순서로 전파\n",
    "- 입력 데이터가 입력층, 은닉층, 출력층을 거치면서 \n",
    "- 예측값으로 변환된 뒤 현재 데이터에 대한 정보는 사라짐 (중간에 저장 안 됨)\n",
    "- 입력 순서에 따라 데이터 간의 종속성이 존재하는 시계열 데이터를 처리하는 데 한계점 존재 \n",
    "\n",
    "\n",
    "- 은닉층의 출력값을 출력층으로도 값을 보내지만, \n",
    "- 동시에 은닉층의 출력값이 다시 은닉층의 입력으로 사용\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN(Recurrent Neural Network : 순환 싱경망)\n",
    "- DFN의 시계열 데이터 처리의 한계점 해결하기 위한 신경망\n",
    "- 유닛 간 연결이 순환적 구조를 이룸\n",
    "- 신경망 내부에 상태를 저장할 수 있게 함으로써\n",
    "- 내부의 메모리를 이용해 시퀀스 형태의 입력 처리\n",
    "- RNN은 은닉층의 노드에서 활성화 함수를 통해 나온 결과값을 \n",
    "- 출력층 방향으로도 보내면서, \n",
    "- 다시 은닉층 노드의 다음 계산의 입력으로 보내는 특징\n",
    "- 문자열, 센서 데이터, 음성인식과 같이 시간적으로 연속성이 있는 데이터 처리에 용이\n",
    "- 층이 많은 네트워크에서 나타나는 그래디언트 소실 문제(vanishing gradient problem) 발생\n",
    "- 오랜 시간에 결쳐 학습시 gradient가 소실하는 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Long Short-Term Memory (LSTM)\n",
    "- 장단기 메모리\n",
    "- RNN에서 발생하는 그래디언트 소실 문제를 해결하기 위해 제안\n",
    "- 실전에서 응용들은 대부분 이 LSTM을 이용하여 구현\n",
    "- 은닉층의 메모리 셀에 입력 게이트, 망각 게이트, 출력 게이트를 추가하여 \n",
    "- 불필요한 기억을 지우고, 기억해야할 것들을 정함\n",
    "- 은닉 상태(hidden state)를 계산하는 식이 \n",
    "- 전통적인 RNN보다 조금 더 복잡해졌으며 셀 상태(cell state)라는 값을 추가\n",
    "- forget gate, input gate, output gate라는 새로운 요소를 은닉층의 각 뉴런에 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN(Convolution Neural Network :  합성곱 신경망)\n",
    "- 최소한의 사전처리를 사용하도록 설계된 다층 퍼셉트론으 한 종류\n",
    "- 하나 또는 여러 개의 합성곱 계측과 그 위에 올려진 일반적인 인공신경망 계층들로 이루어짐\n",
    "- 주로 시각적 이미지를 분석하는 데 사용\n",
    "- 오디오, 시계열, 신호 데이터와 같이 영상 이외의 데이터를 분류하는 데도 효과적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
